"""
Celeryåº”ç”¨é…ç½®
"""
from celery import Celery
from ..core.config_manager import get_config_manager

# è·å–é…ç½®
config_manager = get_config_manager()
task_queue_config = config_manager.get_task_queue_config()
redis_config = config_manager.get_redis_config()

# æ„å»ºRedis URL
redis_host = redis_config.get('host', 'localhost')
redis_port = redis_config.get('port', 6379)
redis_db = redis_config.get('db', 0)
redis_password = redis_config.get('password')

if redis_password:
    broker_url = f"redis://:{redis_password}@{redis_host}:{redis_port}/{redis_db}"
    result_backend = f"redis://:{redis_password}@{redis_host}:{redis_port}/{redis_db}"
else:
    broker_url = f"redis://{redis_host}:{redis_port}/{redis_db}"
    result_backend = f"redis://{redis_host}:{redis_port}/{redis_db}"

# åˆ›å»ºCeleryåº”ç”¨
celery_app = Celery('comfyui_workflow_manager')

# å¦‚æœRedisä¸å¯ç”¨ï¼Œä½¿ç”¨å†…å­˜åç«¯
try:
    import redis
    r = redis.Redis(host=redis_host, port=redis_port, db=redis_db, password=redis_password)
    r.ping()
    # Rediså¯ç”¨ï¼Œä½¿ç”¨Redisä½œä¸ºbrokerå’Œbackend
    final_broker_url = task_queue_config.get('broker_url', broker_url)
    final_result_backend = task_queue_config.get('result_backend', result_backend)
except:
    # Redisä¸å¯ç”¨ï¼Œä½¿ç”¨å†…å­˜åç«¯
    final_broker_url = 'memory://'
    final_result_backend = 'cache+memory://'
    

# é…ç½®Celery
celery_app.conf.update(
    broker_url=final_broker_url,
    result_backend='cache+memory://',  # ä½¿ç”¨å†…å­˜åç«¯ï¼Œé¿å…Redisåºåˆ—åŒ–é—®é¢˜
    task_serializer=task_queue_config.get('task_serializer', 'json'),
    result_serializer=task_queue_config.get('result_serializer', 'json'),
    accept_content=task_queue_config.get('accept_content', ['json']),
    timezone=task_queue_config.get('timezone', 'UTC'),
    enable_utc=task_queue_config.get('enable_utc', True),
    task_routes=task_queue_config.get('task_routes', {}),
    worker_prefetch_multiplier=task_queue_config.get('worker_prefetch_multiplier', 1),
    task_acks_late=False,  # ç¦ç”¨å»¶è¿Ÿç¡®è®¤ï¼Œé¿å…æœªç¡®è®¤ä»»åŠ¡æ¢å¤
    task_reject_on_worker_lost=True,  # Workerä¸¢å¤±æ—¶æ‹’ç»ä»»åŠ¡
    worker_max_tasks_per_child=task_queue_config.get('worker_max_tasks_per_child', 100),

    # ä»»åŠ¡ç»“æœè¿‡æœŸæ—¶é—´
    result_expires=3600,  # 1å°æ—¶

    # ä»»åŠ¡è¶…æ—¶è®¾ç½®
    task_soft_time_limit=1800,  # 30åˆ†é’Ÿè½¯è¶…æ—¶
    task_time_limit=2400,       # 40åˆ†é’Ÿç¡¬è¶…æ—¶

    # ä»»åŠ¡é‡è¯•è®¾ç½®
    task_default_retry_delay=60,    # é‡è¯•å»¶è¿Ÿ60ç§’
    task_max_retries=3,             # æœ€å¤§é‡è¯•3æ¬¡

    # ä»»åŠ¡ä¼˜å…ˆçº§
    task_inherit_parent_priority=True,
    task_default_priority=5,

    # ç›‘æ§è®¾ç½®
    worker_send_task_events=True,
    task_send_sent_event=True,

    # å†…å­˜åç«¯ç‰¹æ®Šé…ç½®
    task_always_eager=final_broker_url == 'memory://',  # å¦‚æœä½¿ç”¨å†…å­˜åç«¯ï¼Œç«‹å³æ‰§è¡Œä»»åŠ¡
    task_eager_propagates=True,
)

# è‡ªåŠ¨å‘ç°ä»»åŠ¡
celery_app.autodiscover_tasks(['app.queue'])


# Workerå¯åŠ¨æ—¶çš„ä¿¡å·å¤„ç†
from celery.signals import worker_ready, worker_shutdown

@worker_ready.connect
def init_worker(sender, **kwargs):
    """Workerå¯åŠ¨å®Œæˆæ—¶åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    try:
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        from ..core.config_manager import get_config_manager
        config_manager = get_config_manager()

        # é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆç¡®ä¿æœ€æ–°é…ç½®ï¼‰
        config_manager.reload_config()
        print("âœ… Celery Worker: é…ç½®æ–‡ä»¶å·²åŠ è½½")

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        from ..database.connection import initialize_database
        mysql_config = config_manager.get_mysql_config()

        if not mysql_config:
            print("âŒ Celery Worker: MySQLé…ç½®ä¸ºç©º")
            return

        # æ£€æŸ¥é…ç½®ç»“æ„
        print(f"ğŸ” Celery Worker: MySQLé…ç½®ç»“æ„: {list(mysql_config.keys())}")

        # ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„æ•°æ®åº“é…ç½®
        required_dbs = ['client', 'admin', 'shared']
        for db_name in required_dbs:
            if db_name not in mysql_config:
                print(f"âŒ Celery Worker: ç¼ºå°‘æ•°æ®åº“é…ç½®: {db_name}")
                return

        # æ„å»ºæ­£ç¡®çš„é…ç½®æ ¼å¼
        database_config = {'mysql': mysql_config}
        initialize_database(database_config)
        print("âœ… Celery Worker: æ•°æ®åº“è¿æ¥å·²åˆå§‹åŒ–")

        # åˆå§‹åŒ–æ•°æ®åº“ä»»åŠ¡çŠ¶æ€ç®¡ç†å™¨
        from ..database.task_status_manager import get_database_task_status_manager
        task_manager = get_database_task_status_manager()
        print("âœ… Celery Worker: æ•°æ®åº“ä»»åŠ¡çŠ¶æ€ç®¡ç†å™¨å·²åˆå§‹åŒ–")

        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        task_manager = get_database_task_status_manager()
        if task_manager:
            print("âœ… Celery Worker: æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            print("âš ï¸ Celery Worker: æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥")

    except Exception as e:
        import traceback
        print(f"âŒ Celery Worker: æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


@worker_shutdown.connect
def cleanup_worker(sender, **kwargs):
    """Workerå…³é—­æ—¶æ¸…ç†èµ„æº"""
    try:
        print("ğŸ”„ Celery Worker: æ­£åœ¨æ¸…ç†æ•°æ®åº“è¿æ¥...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ•°æ®åº“è¿æ¥æ¸…ç†é€»è¾‘
    except Exception as e:
        print(f"âš ï¸ Celery Worker: æ¸…ç†èµ„æºå¤±è´¥: {e}")


def get_celery_app():
    """è·å–Celeryåº”ç”¨å®ä¾‹"""
    return celery_app
